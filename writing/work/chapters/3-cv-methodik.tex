% !TeX root = ../main.tex

\section{Methodik}
\label{sec:cv:methodik}

In diesem Unterkapitel wird die Methodik des Algorithmus zur Lokalisierung und Normalisierung von Dartscheiben in Bildern beliebiger Dimensionen beschrieben. Dieses Kapitel ist dazu in weitere Unterkapitel unterteilt, in denen thematische Abschnitte des Algorithmus auf fortlaufend abstrakteren Daten beschrieben werden. Bevor jedoch in mit der Beschreibung der Arbeitsweise begonnen wird, wird in \autoref{sec:warum_cv} die Frage der Notwendigkeit von der Verwendung herkömmlicher \ac{cv} im Gegensatz zur Verwendung neuronaler Netze für diese Aufgabe geklärt. Danach wird mit \autoref{sec:vorverarbeitung} die Vorverarbeitung der Bilder für den Algorithmus beschrieben. Darauf folgen die Schritte der Kantenerkennung in \autoref{sec:kanten}, in welcher die relevanten Informationen des Bildes extrahiert werden. Nach der Kantenerkennung folgt die Linienverarbeitung in \autoref{sec:linien}, in der die Kanteninformationen zu Linieninformationen überführt und weiter verarbeitet werden. Anschließend wird in \autoref{sec:orientierung} der Schritt der Orientierung beschrieben, in welchem anhand von bekannten Punkten eine Entzerrung der Dartscheibe errechnet wird. Abgeschlossen wird das Kapitel der Methodik mit der Zusammenführung aller Komponenten in \autoref{sec:zusammenfuehrung_aller_komponenten_cv}.

Ein Überblick über die Schritte des Algorithmus ist in \autoref{img:cv_pipeline} in Form eines Flussdiagramms dargestellt. Es sind die verschiedenen Stufen der Verarbeitung zu erkennen, welche in diesem Abschnitt genauer erläutert werden.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{imgs/cv/cv_pipeline.pdf}
    \caption{Schematische Darstellung der \ac{cv}-Pipeline.}
    \label{img:cv_pipeline}
\end{figure}


% -------------------------------------------------------------------------------------------------

\subsection{Motivation der Verwendung herkömmlicher \acl{cv}}
\label{sec:warum_cv}

In dieser Arbeit wird eine strikte Trennung von Normalisierung der Bilddaten und Lokalisierung von Dartpfeilen auf normalisierten Dartscheiben vorgenommen. In der Herangehensweise von \citeauthor{deepdarts} wird eine Netzwerkarchitektur verwendet, die unabhängig von der Eingabegröße der Bilddaten Aufgaben erzeugt, indem ein \ac{fcnn} verwendet wird. Die Identifizierung der Geometrie der Dartscheibe und Einstichpunkte der Dartpfeile werden in einem gemeinsamen Durchlauf ermittelt und die erzielte Punktzahl wird aus diesen ermittelt. In dieser Thesis ist dieser Prozess aufgeteilt in Normalisierung und Lokalisierung, um normalisierte Bilddaten als Eingaben in das neuronale Netz zur Vorhersage der Dartpfeilspitzen zu verwenden. Durch diese Bedingung an Eingabedaten kann die Spanne möglicher Eingabedaten reduziert werden und das Training zielgerichteter ablaufen.

Ein wesentlicher Vorteil der Auslagerung der Dartscheibenfindung in einen algorithmischen Vorverarbeitungsschritt ist neben der thematischen Kapselung der Herangehensweise das Verständnis des Systems. Während neuronale Netze in der Lage sind, beliebige Funktionen zu approximieren, ist ihre Arbeitsweise nicht bekannt und folglich nicht wartbar. Bei einer algorithmischen Lösung ist die Arbeitsweise bekannt und es kann im Fehlerfall nachvollzogen werden, aus welchen Gründen eine Ausführung fehlgeschlagen ist. Dadurch ist eine gezielte Wartung und Erweiterung eines Algorithmus ohne erneutes Training möglich.

Ebenfalls war die Verwendung von \ac{cv} aufgrund der auffälligen Geometrie einer Dartscheibe naheliegend, da sie Ähnlichkeiten mit Schachbrettern aufweist, welche in der \ac{cv} zur Identifizierung von Kameraparametern verwendet werden \cite{cv_general}. Da die Nutzung bekannter Geometrien eine zentrale Arbeitsweise der \ac{cv} darstellt, war die Intuition gegeben, dass auch eine Erkennung eines ähnlich markanten Objekts -- konkret: einer Dartscheibe -- in einem Bild möglich ist. Aus dieser Intuition heraus ist der in diesem Abschnitt beschriebene Algorithmus entwickelt worden.

% -------------------------------------------------------------------------------------------------

\subsection{Vorverarbeitung}
\label{sec:vorverarbeitung}

Die Algorithmen der \ac{cv} arbeiten auf Bildern beliebiger Größe. Da die Dauer der Verarbeitung mit der Größe der Eingabebilder skaliert, ist eine angemessene Skalierung der Eingaben ein relevanter Bestandteil der Laufzeitoptimierung. Damit einher geht jedoch der Verlust von Informationen im Bild, wodurch eine Abwägung zwischen Geschwindigkeit und Genauigkeit notwendig ist. In dieser Arbeit wird eine schrittweise Verkleinerung der Eingabebilder mit Abmessungen $(w, h)$, entsprechend Breite und Höhe, unternommen, bis $\max (w, h) < s_\text{max}$. Dabei werden Eingabebilder jeweils um den Faktor 2 verkleinert, um Artefakte durch Interpolierung zu minimieren. Der Wert von $s_\text{max} = 1.600\,\text{px}$ ist heuristisch ermittelt als geeignetes Mittel zwischen Geschwindigkeit und Genauigkeit.
\nomenclature{$(w, h) \in \mathbb{N}^2$}{Breite und Höhe eines Bildes}
\nomenclature{$s_\text{max} \in \mathbb{N}$}{Maximale Breite bzw. Höhe eines Eingabebildes}

Der Schritt der Vorverarbeitung kann übersprungen werden, indem $s_\text{max} = \infty$ gesetzt wird. Die Laufzeit der Normalisierung kann dadurch jedoch stark beeinträchtigt werden, da die Anzahl der Pixel annähernd quadratisch mit der Größe des Bildes skaliert.

% -------------------------------------------------------------------------------------------------

\subsection{Kantenverarbeitung}
\label{sec:kanten}

Nachdem die Eingabebilder vorverarbeitet sind, werden die wichtigen Kanten im Bild extrahiert. Eingabebilder enthalten neben den für die Normalisierung relevanten Informationen der Dartscheibe Rauschen, das nicht für die Normalisierung notwendig ist. Mit der Kantenverarbeitung wird der Umfang an Informationen stark reduziert und auf die wichtigen Charakteristiken des Bildes limitiert.

Die Schritte der Kantenerkennung sind in \autoref{img:kantenerkennung} dargestellt. Das verwendete Bild stammt aus dem für DeepDarts verwendeten Datensatz und wird ebenfalls im Paper des Systems zur Veranschaulichung von dessen Arbeitsweise genutzt. Im Sinne der Vergleichbarkeit der Systeme wird die Arbeitsweise dieses Algorithmus anhand des selben Bildes veranschaulicht.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{imgs/cv/methodik/edges.pdf}
    \caption{Schritte der Kantenverarbeitung. (1) Input-Bild aus dem DeepDarts-Datensatz \cite{deepdarts-data}. (2) Umwandlung des Bildes in Graustufen. (3) Kontrasterhöhung des Bildes zur Hervorhebung der Unterschiede schwarzer und weißer Felder. (4) Weichzeichnung zur Verminderung von Störungen. (5) Filterung durch Sobel-Filter, gefolgt von Thresholding. (6) Skelettiertes Kantenbild.}
    \label{img:kantenerkennung}
\end{figure}

\subsubsection{Filterung}
\label{sec:filterung}

Für eine universelle Extraktion von Kanten in Bildern existieren Algorithmen und Filter, wie sie bereits in \autoref{sec:kantenerkennung} beschrieben sind. Diese Filter sind für allgemeine Fälle geeignet, in denen das Ziel eine generelle Kantenerkennung ist oder wenig Annahmen über die Kanteninformationen in Eingabebildern getroffen werden können. In dem hier betrachteten Fall liegt der Fokus der Kantenerkennung nicht auf generischen Kanten im Bild, sondern spezifisch auf den Kanten zwischen den Flächen der Dartscheibe. Diese sind charakteristisch für die Dartscheibe und durch ihr festgelegtes Design vorgegeben. Durch die Erkennung dieser Kanten wird darauf abgezielt, den Mittelpunkt und die grobe Orientierung der Dartscheibe zu ermitteln.

Geometrie und Farbgebung der Felder einer Dartscheibe sorgen für starke Gradienten der Pixelintensitäten entlang der Kanten zwischen benachbarten Feldern. Zudem ist bekannt, dass diese Kanten geradlinig verlaufen und weitgehend uniforme Farbbereiche im Bild voneinander trennen, in denen zudem wenig Kanten zu erwarten sind. Auf Grundlage dieser Beobachtungen wird ein untypisch großer Sobel-Kernel mit einer Größe von $15 \times 15$ Pixeln verwendet, dargestellt in \autoref{img:kernel}. Dieser Kernel sorgt für eine gezielte Erkennung der beschriebenen Eigenschaften in Bildern von Dartscheiben.

\begin{figure}
    \centering
    \includegraphics[width=0.3\textwidth]{imgs/cv/methodik/edges_kernel.png}
    \caption{Vertikaler Sobel-Kernel der Größe $15\times15$ zur Identifizierung großer und uniformer Kanten in einem Bild. Helle Pixel stehen für positive, dunkle Pixel für negative Werte.}
    \label{img:kernel}
\end{figure}

Um die gewünschten Charakteristiken hervorzuheben, wird das Eingabebild vor der Kantenerkennung in Graustufen umgewandelt und der Kontrast wird erhöht, um den Unterschied zwischen hellen und dunklen Bereichen zu betonen. Um Rauschen vor der Filterung zu entfernen, wird das Bild weichgezeichnet. Hochfrequente Informationen werden dadurch verworfen und etwaige Unterbrechungen oder Störungen der Kanten zwischen den Feldern verringert. Auf das resultierende Bild wird der beschriebe Sobel-Kernel in horizontaler und vertikaler Richtung angewendet, um Filterreaktionen von Intensitätsänderungen entlang beider Richtungen zu erlangen. Diese werden miteinander kombiniert und durch Thresholding binarisiert. Die Ausgabe ist eine binäre Maske, in denen Pixel des Wertes 1 Kanten im Eingabebild darstellen.

\subsubsection{Skelettierung}
\label{sec:skelettierung}

Das gefilterte Kantenbild der Dartscheibe enthält aufgrund der Verwendung eines großen Kernels redundante Kanteninformationen durch Kanten, die mehrere Pixel breit sind. Diese breiten Kanten werden mittels Skelettierung auf ihre zentrale Kante reduziert \cite{skeletonization}. Bei der Skelettierung werden die existierenden Kanten iterativ verringert, bis eine zentrale Kante ermittelt ist. Dazu wird das Konzept der Erosion verwendet, bei der Cluster von Pixeln in Binärbildern entlang ihrer Kontur verkleinert werden. Nach der Skelettierung des Kantenbildes verbleibt eine minimale Darstellung der extrahierten Kanten. Der verbliebene Informationsgehalt des Bildes wird dadurch auf das für die kommenden Schritte wesentliche reduziert.

% -------------------------------------------------------------------------------------------------

\subsection{Linienverarbeitung}
\label{sec:linien}

An diesem Punkt in der CV-Pipeline sind relevante Kanteninformationen aus dem Bild extrahiert und als minimale binäre Maske vorhanden. Der nächste Schritt zur Normalisierung der Dartscheibe ist das Identifizieren von Linien in der Kantenmaske. Ziel der Linienverarbeitung ist es, eine mathematische Darstellung der radial angeordneten Kanten zu erlangen, die die Felder der Dartscheibe voneinander trennen. Über diese Darstellung wird mittels Transformationen eine erste Stufe der Entzerrung vorgenommen, indem die Winkel dieser Linien aneinander angeglichen werden.

Die Schritte der Linienverarbeitung sind in \autoref{img:linienverarbeitung} dargestellt und auf die jeweiligen Schritte wird in den folgenden Unterabschnitten genauer eingegangen.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{imgs/cv/methodik/lines.pdf}
    \caption{Veranschaulichung der Schritte der Linienverarbeitung. (1) Identifizierung von Linien im Kantenbild. Jede Linie ist zur Visualisierung in einer zufälligen Farbe dargestellt. (2) Extraktion des Mittelpunktes anhand unterschiedlicher Linienwinkel. Jede Klasse von Winkeln ist in einer zufälligen Farbe dargestellt. (3) Filterung der Linien anhand des Mittelpunktes. Verbleibende Linien sind grün hervorgehoben; Feldlinienwinkel $\phi_i$ in blau. (4) Akkumulation der Winkel von Pixeln in gefilterten Linien. Braune Balken sind ungefilterte, blaue Balken gefilterte Werte. (5) Entzerrte Feldlinien. Alle Winkel $\phi_i=18\degree$ sind weiß hervorgehoben.}
    \label{img:linienverarbeitung}
\end{figure}

\subsubsection{Linienerkennung}
\label{sec:linienerkennung}

Um die Dartscheibe anhand von Linien zu entzerren, müssen in einem ersten Schritt Linien ermittelt werden. Für diesen Prozess wird die Hough-Transformation genutzt. Diese ermöglicht die Identifizierung von Liniensegmenten in Bildern und gibt diese als Liste von Start- und Endpunkten zurück: $L_\text{points} = \{(p_{i, \text{start}}, p_{i, \text{stop}})\ \vert \ i \in [0, n_\text{lines}-1]\}$, wobei $n_\text{lines}$ die Anzahl der gefundenen Liniensegmente ist. In \autoref{img:linienverarbeitung} (1) werden erkannte Linien anhand eines Beispielbildes dargestellt. Jeder Linie ist zur Visualisierung eine zufällige Farbe zugeordnet. Zu erkennen ist, dass neben gewünschten langen Linien viele kurze Linien erkannt werden. Der Grund für eine Häufung vieler kurzer Linien liegt in der diskretisierten Darstellung von Pixeln und Ungenauigkeiten durch Verwackelungen, ungerade Feldgrenzen oder Verzerrungen der Kameralinse. Bei dem Prozess der Linienerkennung kann nicht davon ausgegangen werden, dass Linien ideal erkannt werden. Trotz dessen tragen kurze Linien mit hoher Wahrscheinlichkeit wenig relevante Informationen, sodass Linien, die eine geringere Länge als $5\,\text{px}$ aufweisen, herausgefiltert werden.
\nomenclature{$n_\text{lines} \in \mathbb{N}$}{Anzahl gefundener Liniensegmente in einem Bild}
\nomenclature{$L_\text{points} \in \left(\mathbb{R}^{2 \times 2}\right)^n$}{Kartesische Start- und Endpunkte von Liniensegmenten in einem Bild}

Aus den Start- und Endpunkten der Liniensegmente lassen sich unter Verwendung der in \autoref{sec:polarlinien} eingeführten Gleichungen die polaren Darstellungen $L_\text{polar} = \{(\rho_i, \theta_i)\ |\ i \in [0, n_\text{lines}-1]\}$ errechnen mit $\rho_i \in [0,\ \text{diag}(w, h)]$ und $\theta \in [0\degree, 180\degree]$. Wie bereits bei der Einführung der Gleichung erwähnt, sind in dieser Darstellungsform keine Informationen zu Längen der Linien enthalten. Dieser Aspekt wird im folgenden Verarbeitungsschritt zum Vorteil genutzt.
\nomenclature{$L_\text{polar} \in \left(\mathbb{R}^2\right)^n$}{Polare Darstellungen von Liniensegmenten in einem Bild}

\subsubsection{Mittelpunktextraktion}
\label{sec:mittelpunktextraktion}

Anhand der polaren Gleichungen $L_\text{polar}$ wird in diesem Schritt der Mittelpunkt der Dartscheibe ermittelt. Der Mittelpunkt zeichnet sich dadurch aus, dass alle Linien, die zwischen Dartfeldern liegen -- folglich als Feldlinien bezeichnet -- auf diesen gerichtet sind. Unter der Annahme, dass alle Feldlinien in $L_\text{polar}$ vorhanden sind, überschneiden sich eine Vielzahl dieser Linien im Mittelpunkt der Dartscheibe. Insbesondere ist bekannt, dass diese Linien in jeweils unterschiedlichen Winkeln auftreten, deren ungefähren Werte bekannt sind.

Unter Berücksichtigung dieser Beobachtung geschieht ein Binning von $L_\text{polar}$ anhand der Winkel $\theta_i$ in $b=10$ uniforme Bins $B$ der Größe $\frac{180\degree}{b}=18\degree$ mit den Intervallen $ B_i = [i \times \frac{180\degree}{b}, (i+1) \times \frac{180\degree}{b})$. Für jeden dieser Bins wird eine binäre Maske erstellt, auf der die jeweiligen Polarlinien mit einheitlicher Intensität gezeichnet werden. Diese Masken werden anschließend überlagert und weichgezeichnet, um den Einfluss von Ungenauigkeiten zu minimieren. In dem resultierenden Bild zeichnet sich der Punkt $P_\text{max}$ mit dem höchsten Wert dadurch aus, dass durch ihn die meisten Linien verschiedener Richtungen verlaufen. Diese Eigenschaft ist dadurch verfeinert, dass statt beliebiger Kanten gezielt Kanten mit bestimmten Eigenschaften als Grundlage für die Linien dienen. Durch diese Wahl an Eigenschaften ist mit hoher Wahrscheinlichkeit davon auszugehen, dass mit dem Punkt $P_\text{max}$ der Mittelpunkt der Dartscheibe $m_\text{Dart}=(c_x, c_y)$ identifiziert ist.
\nomenclature{$P_\text{max} \in \mathbb{R^2}$}{Kartesischer Punkt mit maximalen Linienüberschneidungen in einem Bild}
\nomenclature{$m_\text{Dart} \in \mathbb{R}^2$}{Mittelpunkt einer Dartscheibe in einem Bild}

Hinsichtlich der Robustheit dieses Algorithmus ist der Fall hervorzuheben, dass Feldlinien durch perspektivische Verzerrungen von den zu erwartenden Winkelintervallen abweichen können. Es kann dadurch zur Einordnung mehrerer Feldlinien in gleiche Bins oder dem Auslassen von Bins führen. Da bei der Ermittlung des Mittelpunktes jedoch nach einem globalen Maximum statt einem bestimmten Zahlenwert gesucht wird, ist ein gewisser Grad an Robustheit gegen nicht oder nicht korrekt gefüllte Bins gegeben.

Visualisiert ist die Extraktion des Mittelpunkts in \autoref{img:linienverarbeitung} (2). Linien gleicher Bins sind in der Visualisierung mit gleichen Farben dargestellt. Zu erkennen ist ein Highlight im Bulls Eye der Dartscheibe, in der sich die Linien der unterschiedlichen Bins überschneiden. Dieses Highlight ist der Mittelpunkt der Dartscheibe.

% Eine Untersuchung zur Änderung der Robustheit durch Variation der Anzahl an Bins bleibt aus, da die Identifizierung des Mittelpunktes mit 10 Bins in den durchgeführten Tests auf Bildern unterschiedlicher Quellen zuverlässig und erfolgreich war.

\subsubsection{Linienfilterung}
\label{sec:linienfilterung}

Die Mengen $L_\text{points}$ und $L_\text{polar}$ umfassen neben den für die Entzerrung relevanten Feldlinien weitere Linien, die nicht relevant für die Geometrie der abgebildeten Dartscheibe sind. Diese werden in diesem Schritt unter Verwendung des Mittelpunktes der Dartscheibe herausgefiltert. Zur Differenzierung zwischen möglichen Feldlinien und Linien, die mit Sicherheit keine Feldlinien sind, wird die Lotfuß-Distanz der Polarlinien zum Mittelpunkt genutzt. Ist eine Linie nicht auf den Mittelpunkt gerichtet, ist sie mit Sicherheit keine Feldlinie.

Die minimale Lotfuß-Distanz zwischen einem Punkt $(\hat{x}, \hat{y})$ und einer Linie in impliziter Form $(ax + by + c = 0)$ ist definiert durch \cite{point_line_distance}:
\begin{align*}
    \text{dist}(ax + by + c = 0, (\hat{x}, \hat{y})) & = \frac{| a \hat{x} + b \hat{y} + c|}{\sqrt{a^2+c^2}}
\end{align*}

Die implizite Form der Geraden lässt sich mit folgenden Gleichungen aus der Polarform berechnen:
\begin{align*}
    \rho          & = x \cos{\theta} + y \sin{\theta}        \\
    \iff 0        & = x \cos{\theta} + y \sin{\theta} - \rho \\
    \Rightarrow a & = \cos{\theta}                           \\
    \Rightarrow b & = \sin{\theta}                           \\
    \Rightarrow c & = -\rho
\end{align*}

Durch Einsetzen dieser ermittelten Variablen in die Distanzberechnung folgt:
\begin{align*}
    \text{dist}(ax + by + c = 0, (\hat{x}, \hat{y})) & = \frac{| a \hat{x} + b \hat{y} + c|}{\sqrt{a^2+c^2}}                                                   \\
                                                     & = \frac{| \cos{\theta} \hat{x} + \sin{\theta} \hat{y} - \rho |}{\sqrt{\cos^2{\theta} + \sin^2{\theta}}} \\
                                                     & = | \cos{\theta} \hat{x} + \sin{\theta} \hat{y} - \rho |
\end{align*}

Mit dieser Gleichung lässt sich für jede ermittelte Polarlinie $(\rho_i, \theta_i) \in L_\text{polar}$ der Abstand zum Mittelpunkt der Dartscheibe $m_\text{Dart}$ ermitteln. Anhand dieses Abstands werden die Linien gefiltert, sodass Linien, die mehr als $10\,\text{px}$ von dem Mittelpunkt entfernt verlaufen, herausgefiltert werden.

Auf diese Weise werden diejenigen Linien $\widetilde{L}_\text{polar}$ und $\widetilde{L}_\text{points}$ ermittelt, die auf den Mittelpunkt der Dartscheibe gerichtet sind und mögliche Teile der Feldlinien sind. Es kann an diesem Punkt jedoch nicht sicher ausgeschlossen werden, dass sich keine Outlier unter den gefilterten Linien befinden. Zu erkennen ist die Existenz von Outliern in den gefilterten Linien in \autoref{img:linienverarbeitung} (3). In dem Beispiel liegen Liniensegmente in den Schriftzügen auf der Dartscheibe, die auf den Mittelpunkt gerichtet sind und kein Teil von Feldlinien sind.
\nomenclature{$\widetilde{L}_\text{polar} \in \left(\mathbb{R}^2\right)^n$}{Gefilterte Liste polarer Linien, die auf den Mittelpunkt der Dartscheibe gerichtet sind}
\nomenclature{$\widetilde{L}_\text{points} \in \left(\mathbb{R}^{2 \times 2}\right)^n$}{Gefilterte Liste kartesischer Start- und Endpunkte von Linien, die auf den Mittelpunkt der Dartscheibe gerichtet sind}

\subsubsection{Feldlinien-Berechnung}
\label{sec:feldlinien_berechnung}

Zur Identifizierung der Winkel $\phi_i$ der Feldlinien wird eine adaptierte Hough-Transformation auf die gefilterten Linien $\widetilde{L}_\text{polar}$ und $\widetilde{L}_\text{points}$ verwendet. In dieser wird für jeden Pixel $p$ aller Linien je Winkel $\theta_{i, p}$ und Abstand $d_{i, p}$ zum Mittelpunkt ermittelt. In einem Akkumulator-Array $A^{360}$ werden die Winkel in 360 Bins mit einer Granularität von $0,5\degree$ aufsummiert, gewichtet invers proportional zu $d_{i, p}$. Dadurch wird Pixeln, die weit von dem Mittelpunkt entfernt liegen, ein geringes Gewicht zugeordnet, da diese einer größeren Wahrscheinlichkeit unterliegen, kein Bestandteil einer Feldlinie zu sein. Ziel der Verwendung von $A^{360}$ ist das Identifizieren von Clustern der Winkel.
\nomenclature{$\phi_i \in \mathbb{R}$}{Winkel der Feldlinie $i$}
\nomenclature{$p \in I$}{Pixel in einem Bild}
\nomenclature{$\theta_{i, p} \in \mathbb{R}$}{Winkel eines Pixels $p$ auf der Linie $i$ zum Mittelpunkt der Dartscheibe}
\nomenclature{$d_{i, p} \in \mathbb{R}$}{Abstand einer Pixels $p$ auf einer Linie $i$ zum Mittelpunkt der Dartscheibe}
\nomenclature{$A^{360} \in \mathbb{R}^n$}{Akkumulator-Array für Winkel}

Zur Minderung von Outliern und zur Festigung der mittleren Winkel wird $A^{360}$ zweifach radial mit einem Fenster von $5\degree$ -- entsprechend 10 Bins -- geglättet. In dem resultierenden Akkumulator werden die 10 größten Peaks $\phi_i$ durch \ac{nms} identifiziert; diese Peaks sind die häufigsten Winkel von Liniensegmenten zum Mittelpunkt der Dartscheibe. Durch die getroffenen Annahmen ist davon auszugehen, dass diese Werte die Winkel der Feldlinien angeben. Eine Darstellung eines Akkumulators $A^{360}$ ist mit \autoref{img:linienverarbeitung} (4) gegeben.

\subsubsection{Winkelentzerrung}
\label{sec:winkelentzerrung}

An dieser Stelle sind Mittelpunkt und Winkel der Feldlinien der Dartscheibe bekannt. Ziel dieses Schrittes ist es, die Winkel der Feldlinien zu normalisieren, sodass die Feldlinienwinkel uniforme Werte besitzen.

Um diese Entzerrung zu erzielen, wird eine Minimierung vorgenommen, in der eine affine Transformation gesucht wird, die diese Winkel bestmöglich aneinander anpasst und auf einen Wert von $18\degree$ angleicht. Diese Optimierung beginnt ausgehend von einer Startlinie und entzerrt alle restlichen Linien iterativ. Die Durchführung geschieht für jede der zehn Feldlinien als Startlinie und die finale Transformation wird berechnet durch den Mittelwert aller ermittelten Transformationen. Im Folgenden wird die allgemeine Transformationssequenz angegeben.

Die erste Teiltransformation ist die Translation des Mittelpunktes $m_\text{Dart}$ in den Koordinatenursprung $O =(0, 0)$. Dieser Schritt ist relevant, da atomare affine Transformationen um $O$ zentriert sind. Darauf folgt die vertikale Ausrichtung der Startlinie $L_s$ mit Winkel $\phi_s$ durch eine Rotation um $-\phi_s$, sodass $\phi'_s = 0\degree$ erzielt wird. Gefolgt wird diese Rotation von der horizontalen Ausrichtung der Orthogonalen $L_o = L_{(s+5) \mod 10}$ durch eine Scherung entlang der Vertikalen. Wichtig bei diesem Schritt ist, dass die vertikale Scherung den Winkel von $\phi'_s$ nicht beeinflusst während eine Ausrichtung $\phi'_o = 90\degree$ erreicht wird. An diesem Punkt sind 2/10 Winkel entzerrt; die restlichen Winkel werden mit einer vertikalen Skalierung derart ausgerichtet, dass ein minimaler Abstand zwischen Zielwinkeln und Feldlinienwinkeln resultiert. Sind alle Feldlinienwinkel perfekt erkannt, ist eine optimale Skalierung möglich, sodass dieser Fehler gleich Null ist. Jedoch ist dies durch u.\,a. Diskretisierung und Artefakte in Linienerkennungen nicht gegeben und ein mittleres Minimum aller Winkeldifferenzen zu ihren Zielpositionen muss gebildet werden. Im Anschluss wird die vertikale Ausrichtung der Startlinie $L_s$ rückgängig gemacht, sodass die $\phi'_s$ seinen Zielwinkel besitzt. Zuletzt wird eine Translation von $O$ auf $m_\text{Dart}$ durchgeführt und die Transformationssequenz ist abgeschlossen.
\nomenclature{$O \in \mathbb{N}^2$}{Koordinatenursprung}
\nomenclature{$L_s \in \mathbb{R}^2$}{Startlinie der Winkelentzerrung}
\nomenclature{$L_o \in \mathbb{R}^2$}{Orthogonale Linie zur Startlinie $L_s$}
\nomenclature{$\phi_o \in \mathbb{R}$}{Feldlinienwinkel der Orthogonalen Linie $L_o$}

Diese Schritte werden für alle Startindizes $s \in [0, 9]$ ausgeführt und die finale Transformation wird durch Mittelwertbildung errechnet. Dadurch wird eine optimale Entzerrung aller Winkel $\phi_i$ erlangt, die nicht durch die Wahl der Startlinie beeinflusst ist. In \autoref{img:linienverarbeitung} (5) ist eine Dartscheibe nach der Entzerrung der Feldlinienwinkel dargestellt. Zu erkennen ist, dass trotz Angleichung der Winkel $\phi_i$ keine Normalisierung der Dartscheibe erreicht ist. Um die Normalisierung zu vollenden, muss die elliptische Dartscheibe in eine runde Form überführt und skaliert werden.
\nomenclature{$s \in \mathbb{N}$}{Indizes für Startlinien der Winkelentzerrung}

% -------------------------------------------------------------------------------------------------

\subsection{Orientierung}
\label{sec:orientierung}

An dieser Stelle in dem Algorithmus ist der Mittelpunkt der Dartscheibe identifiziert und die Winkel der Feldlinien sind normalisiert, jedoch ist an diesem Punkt noch keine korrekte Normalisierung der Dartscheibe gegeben. Durch perspektivische Verzerrungen ist es möglich, dass die Dartscheibe nicht die Form eines Kreises, sondern einer Ellipse besitzt, wie in \autoref{img:dart_ellipse} anhand eines Beispiels dargestellt ist.

\begin{figure}
    \centering
    \includegraphics[width=0.55\textwidth]{imgs/cv/methodik/ellipse.png}
    \caption{Ellipsoide Darstellung einer Dartscheibe mit uniformen Feldlinienwinkeln.}
    \label{img:dart_ellipse}
\end{figure}

Das Vorgehen der Orientierung basiert auf der Grundidee des DeepDarts-Systems, in welchem Orientierungspunkte identifiziert werden, deren Positionen in einem normalisierten Bild bekannt sind. Anhand dieser Punktverschiebungen wird eine Homographie abgeleitet, die eine Transformation des Bildes vornimmt, um diese Punkte auf ihre Zielpositionen zu überführen und die Dartscheibe zu entzerren. Im Gegensatz zu wenigen fest definierten Orientierungspunkten, wie sie in DeepDarts verwendet werden, wird für dieses System eine Vielzahl an Orientierungspunkten identifiziert, um eine wesentlich robustere Entzerrung zu ermöglichen. Die wesentlichen Schritte der Orientierung sind in \autoref{img:orientierung} dargestellt und werden in den folgenden Unterkapiteln genauer erläutert.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{imgs/cv/methodik/orientation.pdf}
    \caption{Schritte zur Orientierung der Dartscheibe. (1) Log-polare Darstellung der Dartscheibe. (2) Identifizierte Eckpunkte. Hervorgehobene Streifen veranschaulichen die erwarteten Bereiche der Feldlinien. (3) Identifizierung und Klassifizierung von Surroundings. Positiv klassifizierte Surroundings sind grün umrandet, negative rot. Weiße Balken an der Seite der Surroundings geben den Score an, der zur Klassifizierung errechnet wird; der Threshold befindet sich auf halber Höhe der Balken. In der oberen linken Ecke befindet sich die mittlere Surrounding. (4) Projektion der identifizierten Orientierungspunkte. Pfeile deuten die Richtung der Verschiebungen an; der graue Ring ist die Trennlinie zwischen inneren und äußeren Punkten. (5) Entzerrte Dartscheibe. Die ideale Entzerrung ist über das Bild gelegt.}
    \label{img:orientierung}
\end{figure}

\newpage
\subsubsection{Identifizierung von Orientierungspunkten}
\label{sec:orientierungspunkte_finden}

Die konkreten Orientierungspunkte werden nach dem Vorbild von DeepDarts ausgewählt und befinden sich an Eckpunkten zwischen Dartfeldern. Diese Punkte sind besonders markant und durch ihre Positionen klar zu identifizieren. Es werden die Kreuzpunkte auf der Innen- und Außenseite des Triple-Rings sowie entlang der Innenseite des Double-Rings identifiziert, was eine Gesamtzahl von bis zu 60 Orientierungspunkten ergibt. Diese Punkte sind dadurch charakterisiert, dass sie an jede existierende Feldfarbe -- schwarz, weiß, rot und grün -- grenzen, was für die Identifizierung genutzt wird.

\paragraph{Log-polare Darstellung}

Für die Identifizierung der Orientierungspunkte wird das Bild in das log-polare Koordinatensystem überführt. Dazu wird das Bild um den Mittelpunkt der Dartscheibe abgewickelt und ausgerollt, sodass sich der Mittelpunkt der Dartscheibe entlang der Bildkante erstreckt. Dartfelder werden dadurch von Teilstücken eines Kreises zu Rechtecken transformiert und es erfolgt eine Parallelisierung der Feldlinien. Durch die Entzerrung der Winkel sind die Feldlinien in der log-polaren Darstellung äquidistant und die Koordinaten der Feldlinien sind bekannt. Auf Grundlage dieses Wissens können die Farben der schwarzen und weißen Felder extrahiert werden. Diese werden genutzt, um die Bestimmung der Lage der Orientierungspunkte zu unterstützen.

\paragraph{Identifizierung von Ecken}

Orientierungspunkte befinden sich an Eckpunkten von Feldern. Dadurch ergibt sich, dass sie bei einer Eckenerkennung stark ausschlagen. Mithilfe der Harris Corner Detection werden Ecken in dem Bild identifiziert und auf Grundlage ihrer Position gefiltert, sodass eine Liste an Eckpunkten entlang der Feldlinien identifiziert wird. Diese Eckpunkte sind potenzielle Orientierungspunkte, sofern ihre Umgebung wie erwartet gestaltet ist.

\subsubsection{Klassifizierung von Orientierungspunkten}
\label{sec:orientierungspunkte_klassifizieren}

Für jeden potenziellen Orientierungspunkt in dem log-polaren Bild der Dartscheibe wird die Surrounding betrachtet. Als Surrounding wird die unmittelbare, quadratische Umgebung um einen potenziellen Orientierungspunkt bezeichnet. Durch sie ist eine Einordnung möglich, ob es sich um einen tatsächlichen Orientierungspunkt handelt oder nicht. Für jede Surrounding wird eine Farbraumtransformation in einen Farbraum mit dem Namen CrYV vorgenommen. Dieser Farbraum setzt sich aus Kanälen unterschiedlicher Farbräume zusammen und ist darauf ausgelegt, die Unterschiede zwischen schwarzen, weißen und bunten Feldern zu verstärken. Dabei wird nicht zwischen rot und grün unterschieden, da sich diese Farben aus den Positionen der schwarzen und weißen Felder ableiten lassen.

Im CrYV-Farbraum werden die mittleren Farbwerte der Ecken aller Surroundings klassifiziert. Durch diese lässt sich einerseits herausfinden, ob ein potenzieller Orientierungspunkt ein Outlier ist, und andererseits, in welcher Orientierung sich dieser befindet. Dazu werden die Ecken anhand heuristisch erarbeiteter Thresholds in die Kategorien schwarz, weiß und farbig eingeordnet. Entspricht eine Surrounding nicht der Erwartung, dass ein schwarzes, ein weißes und zwei farbige Bereiche in diesem liegen, wird der jeweilige Punkt nicht weiter betrachtet. Durch diese Einordnung werden diejenigen Punkte entfernt, die mit großer Wahrscheinlichkeit keine Orientierungspunkte sind.

In einem folgenden Schritt wird eine mittlere Surrounding aller verbliebenen Eckpunkte als Median aller normalisierter Surroundings errechnet. Dieses mittlere Surrounding wird auf zweierlei Arten gegen jede Surrounding verglichen. Die erste Metrik ist der Abstand der Farbwerte im Lab-Farbraum, die zweite Metrik ist der \ac{ssim}-Index. Durch Gewichtung dieser Metriken wird eine pessimistische Kategorisierung der Surroundings in valide und nicht valide unternommen. Dieser Threshold wird dabei sehr strikt gesetzt, um die Wahrscheinlichkeit von Outliern möglichst gering zu halten. Da für eine Homographiefindung lediglich vier Punkte notwendig sind, ist der Verlust einzelner korrekter Orientierungspunkte vertretbar Nach diesem Schritt verbleiben diejenigen Punkte im Bild, die auf den Eckpunkten der Felder liegen und deren Orientierung durch ihre Surroundings bekannt sind.

\subsubsection{Berechnung von Punktverschiebungen}
\label{sec:punktverschiebungen}

Durch die Position und die Farbgebung der Surroundings der klassifizierten Eckpunkte ist eine Rückrechnung auf die Position der Punkte im Ursprungsbild nach der Entzerrung der Feldlinienwinkel möglich. Darüber hinaus ist durch die Orientierung der Surroundings bekannt, ob sich Orientierungspunkte auf der Innen- oder Außenseite eines Rings befinden. Durch diese Informationen lässt sich für jeden Punkt eindeutig zuordnen, auf welcher Position dieser in einem ideal entzerrten Bild liegen muss. Die Unterscheidung zwischen Innenseite des Triple- und Innenseite des Double-Rings lässt sich durch Bildung des Mittelwerts der Orientierungspunkte auf der Außenseite des Triple-Rings ermitteln. Jegliche Punkte, deren Abstand geringer als das $1,2$-fache des entsprechenden Outer-Triple-Orientierungspunkts derselben Feldlinie besitzen, werden als Inner-Triple-Orientierungspunkt klassifiziert, alle anderen als Inner-Double-Orientierungspunkt. Nicht erkannte Outer-Triple-Orientierungspunkte werden durch Interpolierung identifiziert.

Nach diesem Prozess sind Start- und Zielpunkte bekannt und damit einhergehend die Verschiebungen aller Orientierungspunkte. Sofern mindestens 3/60 möglichen Punkten identifiziert sind, ist eine Entzerrung der Dartscheibe möglich, da der Mittelpunkt als vierter Punkt fungiert, um eine Homographie vollständig zu parametrisieren.

\subsubsection{Entzerrung der Dartscheibe}
\label{sec:entzerrung}

Die finale Entzerrung der Dartscheibe geschieht durch Anwendung des RANSAC-Algorithmus. Hintergrund ist die Möglichkeit der Existenz von Outliern in den identifizierten Orientierungspunkten. Als Outlier werden fehlerhaft erkannte Orientierungspunkte bezeichnet, deren Positionen entweder falsch zugeordnet sind oder die sich nicht an Positionen von Orientierungspunkten befinden. Bei der Ableitung einer Homographie auf der Grundlage aller identifizierter Orientierungspunkte sorgen Outlier für Artefakte in der Entzerrung.

Für die Implementierung von RANSAC werden $3 N_\text{OP}$ Homographiefindungen durchgeführt, wobei $N_\text{OP}$ die Anzahl der identifizierten Orientierungspunkte angibt. Für jeden Durchlauf werden zufällig fünf Orientierungspunkte ausgewählt, zu denen der Dartscheibenmittelpunkt hinzugefügt wird. Anhand dieser Punkte wird eine Entzerrungshomographie identifiziert. Nach der Anwendung dieser Homographie werden die Distanzen aller identifizierten Orientierungspunkte zu ihren Zielpositionen bestimmt. Als finale Homographie wird diejenige gewählt, die die geringste Distanzsumme aller Homographien aufweist.
\nomenclature{$N_\text{OP}$}{Anzahl Identifizierter Orientierungspunkte in einem Bild}

Es bleibt festzuhalten, dass der Determinismus der Ausgaben durch die Verwendung von RANSAC nicht mehr gegeben ist. Mehrfaches Ausführen des Algorithmus auf den selben Eingaben kann zu unterschiedlichen Ergebnissen führen.

\subsection{Zusammenführen aller Komponenten}
\label{sec:zusammenfuehrung_aller_komponenten_cv}

An diesem Punkt ist die gesamte \ac{cv}-Pipeline durchgelaufen und es wurden mehrere Transformationsmatrizen für verschiedene Zwischenschritte der Normalisierung ermittelt. Die Reihenfolge der angewandten Transformationen, um die Dartscheibe zu normalisieren, lautet:

\begin{enumerate}
    \item Skalierung der Dartscheibe auf die Berechnungsgröße nach \autoref{sec:vorverarbeitung} (\nameref{sec:vorverarbeitung}): $M_\text{scale}$
    \item Angleichung der Feldlinienwinkel nach \autoref{sec:linien} (\nameref{sec:linien}): $M_\text{align}$
    \item Projektion der Orientierungspunkte auf Ziel-Positionen nach \autoref{sec:orientierung} (\nameref{sec:orientierung}): $M_\text{project}$
\end{enumerate}

Die Aneinanderreihung dieser Transformationen führt zu der finalen Transformation $M_\text{final}$, die wie folgt berechnet wird:
\[ M_\text{final} = M_\text{project} \times M_\text{align} \times M_\text{scale} \]
\nomenclature{$M_\text{scale} \in \mathbb{R}^{3 \times 3}$}{Skalierungstransformation der Eingabebildes der Normalisierung}
\nomenclature{$M_\text{align} \in \mathbb{R}^{3 \times 3}$}{Transformation zur Winkelentzerrung einer Dartscheibe}
\nomenclature{$M_\text{project} \in \mathbb{R}^{3 \times 3}$}{Projektionsmatrix zur Überlagerung der Orientierungspunkte einer Dartscheibe}
\nomenclature{$M_\text{final} \in \mathbb{R}^{3 \times 3}$}{Finale Entzerrungstransformation der Dartscheibe}
Nach der Anwendung dieser Transformation auf das Eingabebild wird das Bild hinsichtlich seine Abmessungen auf die Eingabegröße des neuronalen Netzes zugeschnitten, womit die Normalisierung des Bildes abgeschlossen ist. Der Effekt der Entzerrung anhand des Beispielbildes ist in \autoref{img:cv_input_ouptut} dargestellt. Es sind Eingabe- und Ausgabebild dargestellt, um den Effekt der Normalisierung zu veranschaulichen.

\begin{figure}
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{imgs/cv/methodik/input.jpg}
        \caption{Nicht-normalisiertes Input-Bild.}
        \label{img:cv_input_bild}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering\includegraphics[width=\textwidth]{imgs/cv/methodik/output.png}
        \caption{Normalisiertes Output-Bild.}
        \label{img:cv_output_bild}
    \end{subfigure}
    \caption{Entzerrung eines Beispielbildes aus dem DeepDarts-Datensatz \cite{deepdarts-data}. \autoref{img:cv_input_bild} zeigt das Input-Bild, \autoref{img:cv_output_bild} zeigt das normalisierte Output-Bild nach der Verarbeitung durch die \ac{cv}-Pipeline.}
    \label{img:cv_input_ouptut}
\end{figure}

