% !TeX root = ../main.tex

\chapter{Diskussion}
\label{cha:diskussion}

In diesem Kapitel werden die Ergebnisse und Beobachtungen der Unterprojekte dieser Thesis aufgefasst und miteinander diskutiert, um mögliche Schwachstellen sowie Ungereimtheiten aufzuzeigen. Es wird mit der Diskussion der synthetischen Datenerstellung in \autoref{sec:diskussion:daten} begonnen, gefolgt von der Diskussion zur Normalisierung der Dartscheiben in \autoref{sec:diskussion:cv}. Zuletzt folgt die Diskussion der Verwendung neuronaler Netze zur Identifizierung von Dartpfeilspitzen in normalisierten Bildern in \autoref{sec:diskussion:ki}.

% -------------------------------------------------------------------------------------------------

\section{Diskussion der Datenerstellung}
\label{sec:diskussion:daten}

Mit der Pipeline zur automatischen Datenerstellung ist die Möglichkeit gegeben, realitätsnahe Bilder von Dartscheiben zu erstellen, die zudem korrekt annotiert sind hinsichtlich der Dartpfeilpositionen im Bild sowie der Metainformationen zu dem Bild. Trotz der erzielten Erfolge sind im Verlauf der Arbeit einige Punkte aufgekommen, anhand derer die Datenerstellung erweitert und optimiert werden kann.

\subsection{Datenumfang}

Der Umfang der Daten in Bezug auf ihre Variabilität ist ein relevanter Aspekt der Datenerstellung, da dieser einen wesentlichen Aspekt zur Generalisierung der von dem neuronalen Netz erlernten Charakteristiken auf reale Bilder darstellt.

Ein wesentlicher Kritikpunkt in Bezug auf die Variabilität der Daten ist die Anzahl der möglichen Dartpfeile. Wie in \autoref{sec:dartpfeile_zusammensetzung} beschrieben ist, werden Dartpfeile aus vorgefertigten Bestandteilen zusammengesetzt. Die Anzahl der möglichen Dartpfeile ergibt sich aus der Multiplikation der Anzahlen existierender Ausprägungen der Bestandteile. Es wurden vier Tips, sieben Barrels, acht Shafts und 15 Flights modelliert, wodurch sich eine Gesamtzahl von $3.360$ möglichen Dartpfeilen ergibt, jedoch ist der limitierende Faktor die Wiederverwendung existierender Bestandteile. Das neuronale Netz erfährt während des Trainings nicht mehr als sieben Barrels, wodurch eine Verzerrung der Datenlage nicht auszuschließen ist. Diese Beobachtung kann ein Indiz für ein unterliegendes Overfitting der Erscheinungsbilder der Dartpfeile sein, welches nicht ausgeschöpftes Potenzial der Datenerstellung überschatten kann.

% - Anzahl unterschiedlicher Dartpfeile stark limitiert
% - - Barrels + Shafts stark limitiert -> ggf. Overfitting bei KI-Training

Weiterhin ist die Anzahl der Dartpfeile je Bild ein Aspekt, der strengere Betrachtung vermag. Wie in \autoref{fig:dart_counts} zu sehen ist, verzeichnet die Verteilung der Dartpfeilanzahl je Bild keinerlei Bilder ohne Dartpfeile. Die Notwendigkeit von Bildern ohne Dartpfeile liegt in der Fähigkeit des neuronalen Netzes, eben diese Gegebenheit zu erlernen. Aufgrund der Architektur ist die Ausgabe keiner Dartpfeile möglich, ohne dass dieses Phänomen in den Trainingsdaten liegt, jedoch kann diese Fähigkeit durch explizites Training mit Bildern, die keine Dartpfeile enthalten, weiter vertieft werden.

% - Umfang der Daten
% - - keine Daten ohne Dartpfeile
% - - Fehler bei der Datenerstellung. Möglicherweise Verzerrung der Daten oder nicht ausgeschöpftes Potenzial

Ein weiterer Aspekt des Datenumfangs ist die Verwendung von Hintergründen. Für die Datenerstellung dieser Arbeit wurde ein Pool, bestehend aus $208$ Environment Maps, verwendet, aus dem für jedes Sample eine zufällige Environment Map ausgewählt und in ihrer Rotation und Helligkeit randomisiert wurde. Durch Einbindung weiterer Datenquellen ist eine Vervielfältigung der Hintergründe möglich, die für eine diversere Datenlage sorgen. Ebenso ist die Auswahl der möglichen Beleuchtungen der Szene durch lediglich fünf unterschiedliche Lichtquellen stark limitiert. Obgleich diese Lichtquellen in ihrer Zusammensetzung kombiniert und modifiziert werden, kann die Anzahl der Beleuchtungsmöglichkeiten eine Einseitigkeit in die Daten einfließen lassen.

% - Umgebungen könnten variabler sein
% - - Mehr Hintergründe
% - - unterschiedlichere Beleuchtungen

Zuletzt wird ein statisches Compositing verwendet, in welchem Imperfektionen der Kamera, Kontrast und Rauschen auf das Kamerabild gelegt werden, um es an das Aussehen von Aufnahmen aus Handykameras anzupassen. Die Parameter dieser Nachverarbeitung sind statisch und für alle generierten Daten gleich. Durch Einbindung zufälliger Änderungen kann die Variabilität der Nachverarbeitung erweitert werden, um eine größere Variabilität der Daten zu erzielen. In der Datenerstellung für diese Thesis wurde jedoch eine universelle Nachverarbeitung vorgenommen, durch die ebenfalls eine Einseitigkeit in das Aussehen der Daten eingeflossen sein kann.

% - Statisches Compositing sorgt für Bias
% - - Könnte mit Parametern ausgestattet werden

\vspace*{-0.2cm}
\subsection{Realismus der Daten}

Bei der qualitativen Betrachtung der synthetischen Daten ist eine Differenzierung zwischen realen und synthetischen Daten mit geringer Unsicherheit möglich. Synthetische Aufnahmen sind ohne Probleme als diese zu identifizieren. Zwar ist gezeigt worden, dass diese Daten den Kern der Datenlage realer Aufnahmen einfangen und diese für ein Training eines neuronalen Netzes ausreichen, jedoch ist die Generalisierung der gelernten Charakteristiken und Merkmale auf Bilder realer Dartscheiben nicht reibungslos möglich. Durch starke Augmentierung der Bilder, beispielsweise Kontrastanpassung und Hinzufügen von Rauschen, werden diese Bilder derart verzerrt, dass die Diskrepanz zwischen augmentierten realen und augmentierten synthetischen Bildern gemindert wird, jedoch kann sie auch nicht durch diese Technik gänzlich geschlossen werden.

Für die Texturierung der Objekte wurden vor dem Hintergrund der Variabilität weitestgehend prozedurale Materialien verwendet. Diese bieten den Vorteil, eine beliebige Anzahl unterschiedlicher Erscheinungsbilder darzustellen. Diese Flexibilität wirkt sich jedoch auf den Realismus der Daten aus. Am anderen Ende des Spektrums liegt die Verwendung von Scans realer Objekte. Diese weisen fotorealistische Charakteristiken auf, jedoch minimale bis keine Variabilität. Die Vereinigung von Prozeduralität und Realismus ist ein komplexes Thema, welche viel Zeit und Ressourcen beansprucht. Eine Optimierung der Materialien ist jedoch ein Aspekt, durch welchen die Qualität der Daten weiter gehoben werden kann.

Wie bereits in \autoref{sec:rendering_qualitativ} erwähnt, ist die Umgebung der Dartscheiben ein wesentlicher Aspekt, der den Grad des Realismus stark einschränkt. Bei der Existenz von Objekten wie Lichtring oder Dartschrank im unmittelbaren Hintergrund der Dartscheibe ist ein starker subjektiver Unterschied mit Hinsicht auf den Realismus der Bilder zu erkennen. Das Zusammenspiel von Lichtreflexionen des Hintergrunds und umliegenden Objekten um die Dartscheibe ist ein Aspekt, der in der Datenerstellung kaum vorhanden ist. In Aufnahmen realer Dartscheiben ist dieser Unterschied deutlich zu sehen, indem Dartscheibe und Dartpfeile durch die umliegenden Objekte indirekt beleuchtet werden.

% Realismus
% - nicht fotorealistisch, aber für Training mit KI reicht es
% - - Grundkonzept ist klar
% - - out-of-distribution-Training funktioniert (wie gut?)
% - - Augmentierung so stark, dass Unterschied zwischen realen und generierten Daten verschwimmt (sollte man denken)
% - prozedurale Texturen vs. Scans
% - - Flexibilität vs. Realismus
% - Umgebungen nicht realistisch
% - - andere Objekte auf Dartscheibe / stark beschädigte Dartscheibe / Verzierungen bzw. Dekoration an und um Scheibe / ...
% - - kein direkter Hintergrund der Dartscheibe
% - - - keine Reflexionen des Lichts
% - - - keine Umgebungsbeleuchtung, nur direkt

\vspace*{-0.2cm}
\subsection{Genauigkeit der Datenerstellung}

In \autoref{sec:berechnung_entzerrung} wurde die Herangehensweise der Lokalisierung von Orientierungspunkten der Dartscheibe in dem gerenderten Bild erklärt. Diese beinhaltet das Identifizieren von Pixelclustern, die aus einer binären Maske des Bildes extrahiert werden. Durch die Kameraperspektive und Diskretisierung der Maskenerstellung stimmt der Mittelpunkt der jeweiligen Cluster nicht notwendigerweise mit dem gesuchten Punkt überein, sodass eine minimale Verschiebung um wenige Pixel resultieren kann. Da für die Lokalisierung der Dartscheibe vier Orientierungspunkte verwendet werden, welches die minimale Anzahl notwendiger Punkte zur Berechnung einer Homographie sind, herrscht keine Redundanz für Fehlerkorrektur. Diese Schwachstelle ist bereits bei der Normalisierung der Bilddaten durch DeepDarts kritisiert worden. In diesem Fall beläuft sich der mögliche systematische Fehler jedoch auf wenige Pixel. Die extrahierten Trainingsdaten sind daher nicht makellos.

Dieselbe Technik der Mittelpunktfindung von Pixelclustern in Maskenbildern wird zur Lokalisierung der Dartpfeile verwendet. Das Herunterbrechen einer Fläche, in diesem Fall die Schnittfläche der Dartpfeilspitzen und der Dartscheibe, auf einen Punkt ist grundlegend fehleranfällig, da eine Dimensionsreduktion von zwei Dimensionen (Fläche) auf keine Dimensionen (Punkt) geschieht.

% Genauigkeit
% - Entzerrung nicht 100\,\% genau
% - -> keine *perfekten* Trainingsdaten
% Referenz von \autoref{sec:berechnung_entzerrung}: Ungenauigkeit bei Entzerrung durch Maske -> Kameraperspektive, Diskretisierung, 3D-Objekt-Pixelcluster nicht exakt.

\subsection{Effizienz der Datenerstellung}

Die Geschwindigkeit der Datenerstellung wurde mit 30 Sekunden je Sample errechnet. Dazu wurden die Daten jedoch parallel auf mehreren Grafikkarten erstellt. Die Auslastung der GPUs wurde trotz Erkennung und Einbindung in die Pipeline nicht in der Art ausgeschöpft wie es unter Verwendung der Nutzeroberfläche der Fall war. Scheinbar wurden viele Berechnungen auf die CPU verlagert, die von der GPU hätten übernommen werden können. Durch dieses Bottleneck wurden wesentliche Einbußen in der Geschwindigkeit verzeichnet.

Darüber hinaus ist die Art und Weise des Einlesens und der Berechnung der Randomisierung weitestgehend sequenziell. Parallelisierung der Ausführungsschritte durch vorgezogene Erstellung von Szenenparametern und Ermittlung von Objektparametern während des Renderns von Szenen können für eine Optimierung der Datenerstellung sorgen. Ebenso ist das sequenzielle Rendern der Maskenbilder ein sehr zeitaufwändiger Prozess, der durch Parallelisierung optimiert werden kann.

Darüber hinaus sorgt ein Memory Leak in der Implementierung der Bibliothek \textit{bpy} für zunehmende Speichernutzung bei subsequentem Rendern mehrerer Sample. Zur Umgehung dieses Problems wird die Datenerstellung für jedes Sample neu gestartet, indem das Projekt neu eingelesen wird und jegliche Einstellungen redundant ausgeführt werden müssen. Dadurch ist mit deutlichem Overhead zu rechnen im Vergleich zu sukzessivem Erstellen von Daten.

% Effizienz
% - Erstellung der Bilder könnte schneller verlaufen
% - - Optimierungen bezüglich GPU-Nutzung
% - - keine volle Auslastung der GPU
% - - Parallelisierung / Optimierung der Verwendung der Szene
% - - - aktuell: erneutes Einlesen des gesamten Projekts für jedes Sample + Einstellungen je Sample vornehmen
% - - - Verbesserung: System mit Checkpoints für einfaches Zurücksetzen der Szene, Verringerung von Overhead

% -------------------------------------------------------------------------------------------------

\section{Diskussion der algorithmischen Normalisierung}
\label{sec:diskussion:cv}

Die Erkennung und die Normalisierung der Dartscheiben in Bildern dient als Vorverarbeitungsschritt und ist in dieser Arbeit als gesonderter Schritt in der Inferenz gehandhabt. Bei dieser Vorverarbeitung der Daten sind im Verlauf der Arbeit Aspekte aufgekommen, die in diesem Unterkapitel diskutiert werden.

\subsection{Verwendete Technik}

Mit DeepDarts wurde ein System vorgestellt, welches durch die Verwendung neuronaler Netze zuverlässige Ergebnisse auf Testdaten erzielen konnte. Von diesem Ansatz wurde sich aus Gründen der Flexibilität und des vorhandenen Hintergrundwissens im Bereich der herkömmlichen \ac{cv} gelöst, indem der Prozess zweigeteilt wurde. Die resultierende Aufteilung in algorithmische Normalisierung und Dartpfeilerkennung auf Grundlage neuronaler Netze zieht sowohl Vorteile wie Nachteile mit sich.

Da die Schritte der Normalisierung algorithmisch durchgeführt werden und die Funktionsweise im Gegensatz zur Verwendung neuronaler Netze bekannt ist, kann Fehlerfällen gezielt nachgegangen werden. Jedoch zieht dieser Vorteil einen Schwachpunkt in der Ausführungszeit mit sich. Neuronale Netze arbeiten durch die Verwendung abstrakter Informationen stark parallel, um zu einem Ergebnis zu gelangen. Dem gegenüber stehen algorithmische Methoden, in denen eine geringe Zahl konkreter Informationen sequenziell verarbeitet wird. Durch die starke Parallelität neuronaler Netze ist die Verarbeitung der Daten effizienter als algorithmische Methoden. Die Ausführungszeit der in dieser Thesis erarbeiteten Algorithmen ist durch die sequenzielle Natur der Herangehensweise limitiert. Zudem ist die Implementierung eines Großteils des Algorithmus in einer interpretierten Programmiersprache ein Bottleneck der Performance. Trotz der Verwendung kompilierter Bibliotheken weist dieser Algorithmus weitaus längere Ausführungszeiten auf, als in kompilierten Programmiersprachen zu erwarten ist.

Die Ausführungszeit von DeepDarts beträgt im Mittel zwischen 0,1 und 0,2 Sekunden auf DeepDarts-Daten mit einer festen Größe von $800 \times 800\,\text{px}$ und etwa 0,25 Sekunden auf den gerenderten Daten variabler Größen. Die Ausführungszeit des Algorithmus zur Normalisierung in dieser Arbeit beläuft sich mit etwa 0,3 Sekunden auf DeepDarts-Daten und über 0,4 Sekunden auf den gerenderten Testdaten auf fast die doppelte Dauer. Absolut gesehen ist diese Dauer der Ausführung akzeptabel, jedoch ist dieser Unterschied der Herangehensweise hervorzuheben, insbesondere hinsichtlich der Tatsache, dass mit der Normalisierung lediglich der erste von zwei Schritten zum Scoring vollbracht ist, wohingegen mit DeepDarts die gesamte Vorhersage nach der gemessenen Zeitspanne vollzogen ist.

% Technik
% - ist keine KI
% - - man weiß, wie es funktioniert
% - - man kann es debuggen
% - Dauert lange im Gegensatz zu DD-System / einfacher KI-Inferenz
% - - unfairer Vergleich, da KI auf Graphen kompiliert und optimiert ist; CV ist interpretierter Python-Code

\subsection{Zuverlässigkeit des Systems}

Durch die Analysen in \autoref{sec:cv:ergebnisse} konnte ein hoher Grad der Genauigkeit und Robustheit des Systems aufgezeigt werden. Mitverantwortlich für diesen hohen Grad der Robustheit ist ein durchweg pessimistisches Einschätzen der Resultate und großzügiges Thresholding von Daten. Zur Identifizierung einer Entzerrung der Dartscheibe ist ein Minimum von vier Punkten notwendig, welche aus bis zu 60 Kandidaten erkannt werden können. Resultierend sind lediglich $5\,\%$ der potenziell erkennbaren Orientierungspunkte notwendig für eine Normalisierung. Weiterhin wird RANSAC verwendet, um einen robusten Umgang mit Outliern zu gewährleisten. Die Kombination dieser Techniken sorgt jedoch in speziellen Fällen für fehlerhafte Identifizierungen und kann durch optimierte Prozesse in der Findung der Orientierungspunkte optimiert werden. Ist eine zuverlässige Findung vieler Orientierungspunkte möglich, ist der Einsatz von RANSAC weniger fehleranfällig und es können bessere Entzerrungen gefunden werden.

Ebenfalls wird Nichtdeterminismus durch die Verwendung von RANSAC in das System eingeführt. Der Algorithmus produziert daher keine eindeutigen Resultate, sodass unterschiedliche Durchläufe auf demselben Bild zu unterschiedlichen Ergebnissen führen können. Dieser Nichtdeterminismus sorgt für Ungewissheiten der Vorhersagen des Algorithmus.

Zuletzt ist die Art der Vorverarbeitung der Bilder für den Algorithmus ein Problempunkt, an dem potenziell relevante Informationen verworfen werden. Wie in \autoref{sec:vorverarbeitung} beschrieben, werden Bilder auf eine maximale Seitenlänge von $1.600\,\text{px}$ iterativ um den Faktor zwei verkleinert. Der Hintergrund dieser Skalierung ist der Zeitaufwand der Operationen. Sowohl Genauigkeit wie Berechnungsdauer der Algorithmen skalieren mit der Größe der Bilder. Um eine zeitliche Obergrenze der Berechnungsdauer zu setzen, wurde sich für eine Vorverarbeitung zur Reduktion der Bildgröße entschieden. Der damit einhergehende Informationsverlust im Bild sorgt potenziell für Ungenauigkeiten bei der Berechnung der Normalisierung.

Trotz der erwähnten Kritikpunkte konnte ein weitestgehend zuverlässiger Normalisierungs-Algorithmus erarbeitet werden. Die Erfolgsrate der Findung von Normalisierungen in Bildern beträgt $\geq 97\,\%$, wie in \autoref{sec:findung_normalisierung} dargestellt ist. Zusätzlich ist die Genauigkeit der Normalisierungen mit einer maximalen mittleren Abweichung von $<35\,\text{px}$ ermittelt worden, wie in \autoref{sec:genauigkeit_normalisierung} gezeigt. In Relation zu den Dimensionen des normalisierten Bildes mit einer Größe von $800 \times 800\,\text{px}$ beträgt die Abweichung $<5\,\%$ der Seitenlänge.

Hinsichtlich der DeepDarts-Systeme konnten starke Präferenzen für den Systemen zugewiesene Datensätze dargestellt werden. Die Erfolge der Normalisierungen gelingen bei der Verwendung von DeepDarts-$d_1$ ausschließlich auf den Validierungs- und Testdaten von DeepDarts-$d_1$. Die Genauigkeiten dieser Normalisierungen weisen hingegen die geringsten Abweichungen zu den annotierten Normalisierungen auf. DeepDarts-$d_2$ konnte Normalisierungen auf allen Datensätzen identifizieren, jedoch ist ebenfalls eine starke Präferenz der eigenen Daten zu erkennen, sowohl in der Erfolgsrate als auch in der Genauigkeit. Die mittlere Verschiebung auf gerenderten Daten mit $1.500\,\text{px}$ liegt weitaus über den Abmessungen der Bilder und ist damit nicht als valide Normalisierung einzuordnen. Es ist aus diesen Ergebnissen abzuleiten, dass keine Generalisierbarkeit von DeepDarts auf den Systemen unbekannten Daten erzielt werden kann.

% Zuverlässigkeit
% - nicht 100\,\%, aber ganz gut, wenn es klappt
% - durch RANSAC nicht deterministisch
% - - dadurch aber relativ robust gegen Outlier
% - arbeitet auf skalierten Eingabebildern
% - - Informationsverlust für Zeitgewinn

% -------------------------------------------------------------------------------------------------

\section{Diskussion der Lokalisierung durch Verwendung neuronaler Netze}
\label{sec:diskussion:ki}

Die Erkennung der Dartpfeile geschieht durch ein neuronales Netz, welches in einer eigenen Implementierung durch synthetische Daten trainiert wurde. Dieses neuronale Netz basiert auf einer etablierten Architektur, welche durch Integration eigener Änderungen adaptiert wurde. Durch diese Änderungen wurde eine Spezifizierung des Netzwerks auf die zugrundeliegende Aufgabe vorgenommen. Obgleich diese Herangehensweise Vorteile mit sich zieht, ist eine Adaption etablierter Architekturen ein Aspekt, der kritisch betrachtet werden muss. In den folgenden Unterkapiteln werden Aspekte des Modells und des Trainings diskutiert.

\subsection{Eigene Implementierung des Modells}

Die übliche Handhabung des Trainings einer bereits etablierten Architektur beinhaltet die Verwendung der vortrainierten Netzwerkparameter. Durch die eigene Implementierung zur Adaption der Architektur ist das Zurückgreifen auf die vortrainierten Parameter nicht möglich. YOLOv8 wurde mithilfe von PyTorch entwickelt und implementiert während in dieser Arbeit TensorFlow verwendet wurde. Vortrainierte Modelle beherbergen den Vorteil, deutlich mehr Bildern ausgesetzt gewesen zu sein, sodass die Netzwerkparameter in entsprechendem Einklang miteinander sind, dass eine Vielzahl an Strukturen sinnvoll verarbeitet werden kann. Dieser Startpunkt des Trainings ist im Vergleich zu einem nicht vortrainierten Netzwerk vorteilhaft, da eine generelle Strukturerkennung bereits antrainiert ist und ein erheblicher Teil des Trainings bereits vollzogen ist.

Auch hinsichtlich der Generalisierbarkeit auf neue Situationen ist die Verwendung vortrainierter Netzwerke von Vorteil, da mehr Wissen über nicht in den Trainingsdaten vorhandene Objekte zur Adaption auf die eigene Aufgabe in den Parametern des Netzwerks eingebettet sind. Wird ausschließlich auf eigenen Daten trainiert, ist die Spanne der Generalisierbarkeit durch die Variabilität der eigenen Daten vorgegeben.

% - kein bereits trainiertes Modell genutzt
% - - YOLOv8 wurde mit PyTorch erstellt
% - - eigene Expertise liegt in TensorFlow

\vspace*{-0.1cm}
\subsection{Training des Modells}

Für diese Arbeit wurde sich für ein nahezu ausschließliches \ac{ood}-Training entschieden. Der Hintergrund liegt in der Beschaffung qualitativ hochwertiger und korrekter Daten. Trotz Salting weniger realer Daten besteht der Großteil der Daten aus synthetisch erstellten Bildern. In \autoref{sec:rendering_qualitativ} wurden sichtbare Unterschiede zwischen synthetischen und realen Daten hervorgehoben. Für ein \ac{ood}-Training ist diese Beobachtung ein Indiz dafür, dass ein systematischer Fehler in die Trainingsdaten einfließt, der Einfluss auf die Fähigkeit zur Generalisierung des Netzwerks auf reale Daten haben kann. Obwohl dieser Fehler messbar ist, wie in \autoref{sec:ki:ergebnisse} aufgezeigt, ist die Magnitude der Diskrepanz realer und synthetischer Testdaten lediglich geringfügig.

Bei der Betrachtung der unterschiedlichen Metriken, welche die Funktionsweisen verschiedener Bereiche der Netzwerkarchitektur beleuchten, ist zu vermerken, dass die Identifizierung der Feldfarbe deutliche Differenzen zwischen synthetischen und realen Daten aufzeigt. Dieser Umstand deutet auf eine nicht ausreichende Abdeckung möglicher Feldfarben in der Datenerstellung hin, wodurch ein gewisser Grad der Verzerrung der Trainingsdaten aufgezeigt werden kann.

Trotz der Messbarkeit dieses systematischen Fehlers durch das \ac{ood}-Training ist die Fähigkeit der Übertragung erlernter Charakteristiken synthetischer Daten auf reale Daten gezeigt worden, indem wesentliche Konzepte in synthetischen Daten erlernt und auf reale Daten übertragen werden konnten. Einige Fehlerquellen der Vorhersagen auf realen Daten konnten spezifisch ausfindig gemacht werden. So wurden in vielen Fällen Logos und Markierungen als Dartpfeilspitzen identifiziert, die in dieser Art nicht in den synthetischen Daten vertreten waren. Ebenso wurden Abnutzungsspuren in den Dartfeldern gelegentlich als Dartpfeile identifiziert, deren Erscheinungsbilder nicht durch die Simulationen der Datenerstellungen abgedeckt sind.

% - striktes Out-of-distribution-Training möglicherweise nicht optimal
% - - sichtbarer Unterschied in unterschiedlichen Quellen aus Validierungsdaten
% - - generierte Validierungsdaten deutlich besser erkannt als reale Aufnahmen
% - - sichtbare Schwachpunkte von Out-of-distribution-Training

\vspace*{-0.1cm}
\subsection{Vergleich mit DeepDarts}

Die für DeepDarts trainierten Modelle belaufen sich auf eine Größe von je ca. $6$ Millionen Parameter; das in dieser Thesis trainierte Netzwerk umfasst etwa $10,\!5$ Millionen Parameter. Der Aufgabenbereich des Modells von DeepDarts umfasst das Identifizieren von Dartpfeilen sowie von Orientierungspunkten in nicht normalisierten Bildern. Die Anforderung an das neuronale Netz in dieser Thesis beinhaltet die Identifizierung von Dartpfeilen und den Farben der getroffenen Felder in normalisierten Bildern. Sowohl die Parameterzahlen wie auch die zu bewältigenden Aufgaben der Netzwerke weichen signifikant voneinander ab. Während die Aufgaben für DeepDarts mehr Komplexität umfassen und zugleich weniger Parameter für die Umsetzung vorhanden sind, ist die Wahl von mehr Parametern für dieses System und seine Aufgaben nicht unbegründet. Mit DeepDarts konnte durch starkes Overfitting lediglich eine untere Schranke in Bezug auf die Parameterzahl ermittelt werden. Die wesentlich diversere Datenlage dieser Thesis erfordert mehr Parameter in einem Netzwerk, um ähnliche Ergebnisse zu erzielen.

% - größeres Modell als Referenz-Paper
% - - ~6 M vs. ~10 M Parameter
% - - Aufgabe ist aber auch komplexer
% - - - DD-KI unterliegt starkem Daten-Bias und ist stark overfitted
