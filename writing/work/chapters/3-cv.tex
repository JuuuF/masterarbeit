% !TeX root = ../main.tex

\chapter{Vorverarbeitung von Bildern durch klassische Computer Vision}
\label{cha:cv}

Sowohl für das Training als auch für die Inferenz werden normalisierte Bilder von dem neuronalen Netz erwartet. Diese Normalisierung kann auf unterschiedliche Arten geschehen; für das DeepDarts-System wurde sich entschieden, die Normalisierung und Vorhersage der Dartpfeilpositionen in einem Schritt von dem neuronalen Netz zu übernehmen. Dieser Ansatz geht jedoch mit einigen Schwachpunkten einher. Wesentliche Nachteile wurden offensichtlich in Hinsicht auf den Verlust von Informationen durch Herunterskalierung des Bildes, um dem Input des neuronalen Netzes gerecht zu werden, und die Identifizierung spezifischer Fixpunkte, die möglicherweise verdeckt sein könnten. Darüber stützt sich eine Abwälzung eines Problems auf ein neuronales Netz auf die Korrektheit und den Umfang der für das Training genutzten Daten. Durch gewollte oder ungewollte Einbindung einer verzerrten Datenlage erlernt ein neuronales Netz eben diese Eigenheiten und es besteht die Gefahr des Overfittings, sodass eine Verallgemeinerung der System-Performance mit großem Mehraufwand des weiteren Trainierens des Systems verbunden ist.

Eine algorithmische Herangehensweise an ein solches Problem ist im Gegensatz zu einem neuronalen Netz keine Blackbox und die innere Arbeitsweise ist bekannt und klar definiert. Es kann strikt nachvollzogen werden, an welcher Stelle und aus welchem Grund eine fehlerhafte Vorhersage vorkommt und diese Problemquellen können gezielt angegangen werden. Darüber hinaus kann eine algorithmische Normalisierung von Daten ohne den Mehraufwand neuen Trainings eines neuronalen Netzes auf neue Daten erweitert werden. Dazu sind darüber hinaus lediglich wenige Beispiele neuer Daten notwendig, um die Arbeitsweise des Systems anzupassen.

Aus diesen Gründen wurde sich in dieser Thesis für eine algorithmische Normalisierung der Daten entschieden, die nach der Datenerstellung den zweiten Themenbereich ausmacht. In diesem Kapitel werden in einem ersten Schritt die für das Verständnis des Algorithmus notwendigen Grundlagen in \autoref{sec:cv:grundlagen} erläutert. Darauf folgend wird in \autoref{sec:cv:methodik} auf die Methodik der Normalisierung eingegangen und anschließend wird auf einige relevante Themen der Implementierungen eingegangen; \autoref{sec:cv:implementierung}. Zuletzt werden die Ergebnisse dieser Normalisierung anhand idealer Entzerrungen ausgewertet und mit dem Ansatz des DeepDarts-Systems verglichen.

Ein Überblick über die Schritte des Algorithmus ist in \autoref{img:cv_pipeline} dargestellt.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{imgs/cv/cv_pipeline.pdf}
    \caption{CV-Pipeline}
    \label{img:cv_pipeline}
\end{figure}

\input{chapters/3-cv-grundlagen.tex}
\input{chapters/3-cv-methodik.tex}
\input{chapters/3-cv-implementierung.tex}
\input{chapters/3-cv-ergebnisse.tex}
